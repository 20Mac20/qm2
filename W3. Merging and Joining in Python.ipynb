{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"W3. Merging and Joining in Python.ipynb","provenance":[],"collapsed_sections":["K1VdYJJ1S6iO","p-nMMNZkS6iu","7jbHLNWJS6iu","qFwsma6tS6jC","CPb3I6u1S6jJ","l_hXvqvdS6jO","NegFX-rjS6jY"]}},"cells":[{"cell_type":"markdown","metadata":{"id":"6fah6VTyS6hd"},"source":["## Quantitative Methods 2:  Data Science and Visualisation\n","## Workshop 3: Merging and Joining Data in Python\n","\n","Sometimes, we will want to combine data from different sources about the same subject - perhaps we want to compare the GDP in a country with life expectancy, or the proportion of free schools meals with the level of unemployment.\n","\n","### Aims\n","- Understand joins\n","- Work with joining dataframes in Pandas\n","- Create your own examples"]},{"cell_type":"markdown","metadata":{"id":"XdibOrmwS6he"},"source":["## Downloading the Data\n","Let's grab the data we will need this week from our course website and save it into our data folder. If you've not already created a data folder then do so using the following command. \n","\n","Don't worry if it generates an error, that means you've already got a data folder.\n"]},{"cell_type":"code","metadata":{"id":"I50UwMZMS6hf"},"source":["!mkdir data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gyAVkq3xS6hj"},"source":["!mkdir data/wk3\n","!curl https://s3.eu-west-2.amazonaws.com/qm2/wk3/UN_Life_all.csv -o ./data/wk3/UN_Life_all.csv\n","!curl https://s3.eu-west-2.amazonaws.com/qm2/wk3/UN_Cities_1214_country.csv -o ./data/wk3/UN_Cities_1214_country.csv\n","!curl https://s3.eu-west-2.amazonaws.com/qm2/wk3/UN_Cities_1214_population.csv -o ./data/wk3/UN_Cities_1214_population.csv"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tuOYWYbUS6hm"},"source":["## Joining Instructions\n","\n","Joins are the combination of different datasets, and are common in relational databases as a way of performing queries. There are lots of examples of why and when we might want to do this, but most start with two tables of data. We're going to start with some data we've generated.\n","\n","I'm going to go back and work with fake data for a while, because it's clean and small and we can see what's going on - when we work with real data, we have to take great care that the data is clean, the indices match, and so on."]},{"cell_type":"code","metadata":{"id":"UdRoLsYhS6hm"},"source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import random\n","%matplotlib inline\n","plt.style.use('ggplot')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LOltFFwmS6hp"},"source":["Let's create dataframes which represent fictitious values associated with people. Let's assume our data is anonymised because we're ethical researchers and don't want information about real people leaking out."]},{"cell_type":"code","metadata":{"id":"RnB2LIRvS6hp"},"source":["people1 = pd.DataFrame(5+np.random.randn(5, 5))\n","people1.columns = ['units of alcohol drunk','cigarettes smoked','sleep per night','height','BMI']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CKiFh3BkS6hs"},"source":["people1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fjUbAFEFS6hv"},"source":["people2 = pd.DataFrame(5+np.random.randn(3, 5))\n","people2.columns = ['units of alcohol drunk','cigarettes smoked','sleep per night','height','BMI']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VpCJny82S6hy"},"source":["people2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DJh0iZU3S6h1"},"source":["# Adding new observations\n","\n","It looks as if we have some data about people (although we've just made it up), and a set of common measurements. It would be nice to have all of this in one place, so let's *merge* them into one dataframe. We'll use the *concat* command, which is short for *concatenate*, or \"chain together\"."]},{"cell_type":"code","metadata":{"id":"FLd5xBDeS6h1"},"source":["people3 = pd.concat([people1,people2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hKOqzkyJS6h3"},"source":["people3"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lv4myEKXS6h6"},"source":["### What is the problem above? "]},{"cell_type":"code","metadata":{"id":"aPkZTYWGS6h6"},"source":["people4 = pd.concat([people1,people2], ignore_index=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1TEx5aX3S6h9"},"source":["people4"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"caWsFFxQS6h_"},"source":["`ignore_index` is very useful when we want a new DataFrame which only contains data from other DataFrames, but unrelated otherwise."]},{"cell_type":"markdown","metadata":{"id":"wTxlLjkOS6iA"},"source":["## Data with a unique index: adding new observations\n","\n","Let's now examine data where the elements of study are not anonymous. Let's consider that we have some city data. If we have city names (or equivalent) in the index column, simply concatenating them would be fine, because the names would not repeat in the way the index has above."]},{"cell_type":"code","metadata":{"id":"tqM3BIJSS6iA"},"source":["df1 = pd.DataFrame(5+np.random.randn(5, 5))\n","df1.columns = ['area','population','mean temperature','elevation','annual rainfall']\n","df1.index = ['London', 'Paris', 'Beijing', 'Medellin', 'Port Elizabeth']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UCiCbYc2S6iC"},"source":["df1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q2MivfZPS6iF"},"source":["df2 = pd.DataFrame(5+np.random.randn(3, 5))\n","df2.columns = ['area','population','mean temperature','elevation','annual rainfall']\n","df2.index = ['Mumbai', 'Sydney', 'Boston']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"57DmpIiAS6iH"},"source":["df2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3kxmpWRDS6iK"},"source":["df3 = pd.concat([df1,df2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5qSJVJEdS6iM"},"source":["df3"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K1VdYJJ1S6iO"},"source":["## Exercise: Concat continued\n","\n","Repeat the above for fictitious values for New York, Tokyo, Manila and Budapest - concatenate into a new dataframe \"df\"."]},{"cell_type":"markdown","metadata":{"id":"_V4E81NFS6iO"},"source":["## Combining on Attributes\n","\n","What if we're looking at the same locations but different attributes? Consider the same df1"]},{"cell_type":"code","metadata":{"id":"RY6pB5VNS6iO"},"source":["df1 = pd.DataFrame(5+np.random.randn(5, 5))\n","df1.columns = ['area','population','mean temperature','elevation','annual rainfall']\n","df1.index = ['London', 'Paris', 'Beijing', 'Medellin', 'Port Elizabeth']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RUhGQIVKS6iQ"},"source":["df1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mIL7nRfIS6iS"},"source":["But a new dataframe df4, which details the same locations, but has different information about them:"]},{"cell_type":"code","metadata":{"id":"Iegqp8xGS6iS"},"source":["df4 = pd.DataFrame(5+np.random.randn(5, 3))\n","df4.columns = ['Mean House Price', 'median income','walkability score']\n","df4.index = ['London', 'Paris', 'Beijing', 'Medellin', 'Port Elizabeth']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rbAmWwAQS6iV"},"source":["df4"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0qqCGLRNS6iX"},"source":["We have to join \"on\" the index - meaning when merging the records, python will look at the index column."]},{"cell_type":"code","metadata":{"id":"WYmpWEtDS6iY"},"source":["df_joined = df1.merge(df4, left_index=True, right_index=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vza_xrYaS6ic"},"source":["df_joined"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EooLXZTQS6ie"},"source":["Note that this joins on the *index*, not the row number - so if the order of elements in df4 is different, it should still work."]},{"cell_type":"code","metadata":{"id":"n_91cClkS6ie"},"source":["df4 = pd.DataFrame(np.random.randn(5, 3))\n","df4.columns = ['Mean House Price', 'median income','walkability score']\n","df4.index = ['Paris','Port Elizabeth', 'Beijing', 'Medellin', 'London']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mqMP2oAXS6ig"},"source":["df1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A8NaT1CUS6ii"},"source":["df4"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lIvjGPVPS6ik"},"source":["    "]},{"cell_type":"code","metadata":{"id":"w2x9D_uqS6ik"},"source":["df_joined = df1.merge(df4, left_index=True, right_index=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"id3wkaJ-S6im"},"source":["df_joined"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3K9QAAtIS6io"},"source":["## Merge Records\n","Consider now a case where we have data for some but not all cities; so df1 stil has data for these 5 cities:"]},{"cell_type":"code","metadata":{"id":"3wuan3iVS6ip"},"source":["df1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hb9KFYoWS6ir"},"source":["But our new table, df5, contains data for three cities:"]},{"cell_type":"code","metadata":{"id":"HF4QTxXyS6ir"},"source":["df5 = pd.DataFrame(5+np.random.randn(3, 3))\n","df5.columns = ['Mean House Price', 'median income','walkability score']\n","df5.index = ['London', 'Paris', 'Glasgow']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XDqn6RpqS6it"},"source":["df5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p-nMMNZkS6iu"},"source":["## Exercise:\n","\n","How many cities appear in: \n","- both dataframes\n","- only df1\n","- only df5\n","- neither df1 nor df5?"]},{"cell_type":"markdown","metadata":{"id":"7jbHLNWJS6iu"},"source":["## Way Back Venn \n","\n","What is the mechanism for joining data where these mismatches exist? Well, there are several, starting with the..."]},{"cell_type":"markdown","metadata":{"id":"XjGv-0WiS6iv"},"source":["## Inner Join:"]},{"cell_type":"code","metadata":{"id":"3tm0ueElS6iv"},"source":["from IPython.display import Image\n","\n","data_path = \"https://s3.eu-west-2.amazonaws.com/qm2/wk3/inner.png\"\n","Image(data_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zqOCeIaQS6ix"},"source":["(Image from http://blog.codinghorror.com/a-visual-explanation-of-sql-joins/)"]},{"cell_type":"markdown","metadata":{"id":"WAqZJFC0S6ix"},"source":["The inner join *only* includes data whose index appears in both tables. Let's see what that looks like:"]},{"cell_type":"code","metadata":{"id":"db9q4sgPS6ix"},"source":["df_joined = df1.merge(df5, left_index=True, right_index=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ADhCAjIS6iz"},"source":["df_joined"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G6sp9kBzS6i0"},"source":["Here, we have a couple of arguments specifying the manner of the join - we have specified that we are joining on the index of the left and right dataset with the optional \"left_index=True\" and \"right_index=True\". Less obviously, the **left** dataset is df1 (because we're using *df1.merge()* and the **right** dataset is df5 (because it appears as an argument in merge(). There's no special reason it shouldn't be the other way around, but for this function, it is this way around and we need to remember that when we use it. "]},{"cell_type":"markdown","metadata":{"id":"-_Cw_x_-S6i1"},"source":["## Inner Space\n","\n","Although we haven't specified it, the merge() function has defaulted to an inner join (like the diagram above). We can specify how the join is calculated by changing the text in the optional argument \"how\":"]},{"cell_type":"code","metadata":{"id":"DgUf5p2aS6i2"},"source":["df_joined = df1.merge(df5, left_index=True, right_index=True, how='inner')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hSGBUxd-S6i4"},"source":["df_joined"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HXo07YMZS6i6"},"source":["## The Future of The Left\n","The *left* join includes **all** rows where the index appears on the **left** hand side of the join, and **any** data which **matches** it on the **right** hand side. If the index appears on the left but not the right, it will include the data from the left table, and have blanks for the columns on the right. "]},{"cell_type":"code","metadata":{"id":"_Fzj1fzLS6i7"},"source":["data_path = \"https://s3.eu-west-2.amazonaws.com/qm2/wk3/left.png\"\n","Image(data_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uBYPSwlxS6i9"},"source":["What does *this* look like? We will use the *how='left'* optional argument to create a left join:"]},{"cell_type":"code","metadata":{"id":"F3hxwEZxS6i-"},"source":["df_joined = df1.merge(df5, left_index=True, right_index=True, how='left')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7jVbmtsYS6jA"},"source":["df_joined"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EzNh3WeSS6jC"},"source":["As we see, the missing data appears as **NaN** - Not a Number."]},{"cell_type":"markdown","metadata":{"id":"qFwsma6tS6jC"},"source":["## Exercise:\n","\n","Carry out *right* and *outer* joins on the dataframes df1 and df5 and explain how they're filtering and joining the data. "]},{"cell_type":"markdown","metadata":{"id":"6Kw7EO9pS6jC"},"source":["## I Am The One and Only\n","\n","So far, we've carried out joins on data which have a *one-to-one* relationship; data for cities or people. What if our data has a *one-to-many* correspondence? \n","\n","*Example:* We want to look at the quality of life in cities (a real student project from 2014). We have a dataset listing city-level characteristics for a number of cities in Europe, including the country each city is in. We also have a dataset listing the GDP, life expectancy and other indicators for a number of *countries* in Europe. How do we create a dataframe which, for each city, lists all of the characteristics of a city and those of its parent country?"]},{"cell_type":"markdown","metadata":{"id":"FBuvIDuUS6jC"},"source":["We'll be working now with data from the UN, covering information about cities - real data this time. The UN has some great data, we've taken some from here and processed it in various ways:\n","\n","http://data.un.org/Data.aspx?d=POP&f=tableCode%3A240\n","\n","Let's load up data on city population - this set contains data for 2012-2014 inclusive:"]},{"cell_type":"code","metadata":{"id":"OT9bs-RKS6jD"},"source":["data_path = \"./data/wk3/UN_Cities_1214_population.csv\"\n","\n","city_pop = pd.read_csv(data_path, encoding='latin1')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KrxMQsfcS6jF"},"source":["city_pop.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hOKGwwvbS6jH"},"source":["## Exercise\n","\n","There is a another datafile we downloaded called *UN_Cities_1214_country.csv*. This is saved to *./data/wk3/UN_Cities_1214_country.csv* - Load this into a dataframe called *city_c* with the city name as the index and view it; then, using *merge* on city name with city_pop to create a new dataframe called *cities*.\n","\n","**Hints:**\n","You'll notice that the index **won't** be the column you want to merge on in the city_pop data. What column *should* you merge on in city_pop? Which column should you merge on in city_c?\n","\n","The syntax for merging on a **column** (which is not the index) is to pass the column name to the optional 'left_on=' or 'right_on=' arguments. And we don't use right_index=True (or left_index=True), depending on which we're using.\n","\n","So for example: **df1.merge(df2, left_on='Name', right_index=True)** would join df1 (on the left) to df2 (on the right), using the column 'Name' on the left (df1) and the index column (whatever that is) on the right (df2)."]},{"cell_type":"code","metadata":{"id":"hbQwHwaSS6jH"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CPb3I6u1S6jJ"},"source":["## A footnote about footnotes\n","\n","Just a quick note - if you look at the primary UN data, you'll see footnotes which will confuse the hell out of Pandas. I've taken the footnotes out, but you can use .tail() to see whether there's any junk in the trunk, and remove it via a text editor."]},{"cell_type":"markdown","metadata":{"id":"4mRhI_8mS6jJ"},"source":["## Clean data\n","We need to simplify this data a bit in the following ways:\n","\n","1. I'm going to focus on one year (2012)\n","2. I'm going to just look at \"Both Sexes\" (not focus on one gender)\n","3. I'm going to get rid of a column of data (the 'Value Footnotes' column) using the *drop()* method. "]},{"cell_type":"code","metadata":{"id":"tI1T3tHxS6jK"},"source":["cities = cities[cities['Sex']=='Both Sexes']\n","cities = cities[cities['Year']==2012]\n","cities.drop('Value Footnotes', axis=1, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vq5LWR9WS6jM"},"source":["cities.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l_hXvqvdS6jO"},"source":["## Extension: In My Place\n","\n","The command I used to get rid of that column is *cities.drop('Value Footnotes', axis=1, inplace=True)*. The syntax is not so complex - the first argument, *'Value Footnotes'*, is just the name of the column; the second argument,  *axis=1*, tells Pandas to look for a column to remove (instead of a row which has *axis=0*); the third and final argument, *inplace=True*, is a command that tells Pandas to edit *inplace*, i.e. to edit the dataframe (*cities*) directly. When *inplace* is False (the default), this command does not directly edit cities, but instead provide an output. So the syntax for that would be \n","\n","new_cities = cities.drop('Value Footnotes', axis=1)\n","\n","and new_cities would be a version of *cities* without the offending column. This is usually the safer option."]},{"cell_type":"markdown","metadata":{"id":"3Z5yN-D6S6jO"},"source":["## Life, Oh Life\n","\n","The UN also has useful data by country, so let's try and work with some of that and join it up with our city data. Let's work with Life Expectancy Data:\n","\n","http://data.un.org/Data.aspx?d=WDI&f=Indicator_Code%3ASP.DYN.LE00.IN"]},{"cell_type":"code","metadata":{"id":"xJ3lzAz-S6jO"},"source":["data_path = \"./data/wk3/UN_Life_all.csv\"\n","life = pd.read_csv(data_path, index_col=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IA9Jy3xJS6jQ"},"source":["life.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"je4DUR8LS6jS"},"source":["## Exercise:\n","\n","In a new cell, clean up the above dataframe by\n","\n","- removing the \"Value Footnotes\" Column\n","- use only the most recent data (2012)"]},{"cell_type":"markdown","metadata":{"id":"2se0IelGS6jS"},"source":["Let's make it a little clearer what \"Value\" refers to, by renaming the column. This is one way to do that:"]},{"cell_type":"code","metadata":{"id":"234BRNRyS6jS"},"source":["life.rename(columns={'Value':'Life Expectancy'}, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lb01c6upS6jV"},"source":["life.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g6MsCtJwS6jW"},"source":["# Exercise\n","\n","Now, merge this data with the cities data to show life expectancy for each city (based on the country it is in), and show the first 5 rows. \n","\n","How much data was \"missing\" in the merge?\n","\n","Relabel the City Population column so it's clear what it represents.\n","\n","\n","**Extension:** Plot population against life expectancy. Use plot's *optional arguments* to specify the x column, y column, and that kind='scatter'. \n","\n","**Don't forget to include a title and axis labels!**\n","\n","How does London fit in this trend? What are the problems with doing this?"]},{"cell_type":"code","metadata":{"id":"_OXM4uygS6jW"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NegFX-rjS6jY"},"source":["## Recap: Joins\n","\n","Pandas has **four** join methods:\n","\n","    - Left Join: use **only** keys from **left** DataFrame. SQL: [left outer join](http://goo.gl/JICveI)\n","    - Right Join: use **only** keys from **right** DataFrame. SQL: [right outer join](http://goo.gl/TrrHjQ)\n","    - Outer Join: use union of **keys from both** DataFrames. SQL: [full outer join](http://goo.gl/bVRqO8)\n","    - Inner Join: use **intersection of keys** from both DataFrames. SQL: [inner join](http://goo.gl/Cf1MF8)"]}]}