{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative Methods 2:  Data Science and Visualisation\n",
    "\n",
    "## Workshop 8: Working with Spatiotemporal Data\n",
    "In this workshop, we will work with data that information about space and time, and show different ways of presenting this data, with the goal of producing fully-fledged maps.\n",
    "\n",
    "### Aims:\n",
    "\n",
    "- Plot and summarise spatial data\n",
    "- Create simple point maps\n",
    "- Understand the basics of projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopandas\n",
      "  Downloading geopandas-0.3.0-py2.py3-none-any.whl (888kB)\n",
      "\u001b[K    100% |################################| 890kB 1.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting shapely (from geopandas)\n",
      "  Downloading Shapely-1.6.1-cp27-cp27mu-manylinux1_x86_64.whl (8.4MB)\n",
      "\u001b[K    100% |################################| 8.4MB 145kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting descartes (from geopandas)\n",
      "  Downloading descartes-1.1.0-py2-none-any.whl\n",
      "Requirement already satisfied: pandas in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from geopandas)\n",
      "Collecting pyproj (from geopandas)\n",
      "  Downloading pyproj-1.9.5.1.tar.gz (4.4MB)\n",
      "\u001b[K    100% |################################| 4.4MB 290kB/s eta 0:00:01                | 1.3MB 60.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fiona (from geopandas)\n",
      "  Downloading Fiona-1.7.9.post1-cp27-cp27mu-manylinux1_x86_64.whl (48.4MB)\n",
      "\u001b[K    100% |################################| 48.4MB 23kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from descartes->geopandas)\n",
      "Requirement already satisfied: python-dateutil in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from pandas->geopandas)\n",
      "Requirement already satisfied: pytz>=2011k in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from pandas->geopandas)\n",
      "Requirement already satisfied: numpy>=1.7.0 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from pandas->geopandas)\n",
      "Collecting munch (from fiona->geopandas)\n",
      "  Downloading munch-2.2.0.tar.gz\n",
      "Collecting click-plugins (from fiona->geopandas)\n",
      "  Downloading click-plugins-1.0.3.tar.gz\n",
      "Requirement already satisfied: six in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from fiona->geopandas)\n",
      "Requirement already satisfied: enum34 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from fiona->geopandas)\n",
      "Collecting cligj (from fiona->geopandas)\n",
      "  Downloading cligj-0.4.0-py2-none-any.whl\n",
      "Requirement already satisfied: functools32 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from matplotlib->descartes->geopandas)\n",
      "Requirement already satisfied: subprocess32 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from matplotlib->descartes->geopandas)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from matplotlib->descartes->geopandas)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=1.5.6 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from matplotlib->descartes->geopandas)\n",
      "Requirement already satisfied: click>=3.0 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from click-plugins->fiona->geopandas)\n",
      "Building wheels for collected packages: pyproj, munch, click-plugins\n",
      "  Running setup.py bdist_wheel for pyproj ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/85/dd/2f/d1ed07a507c7adb330cda0afcc96cae8e9abb4d85bbb788bdf\n",
      "  Running setup.py bdist_wheel for munch ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/6b/a7/c4/fee97ae4038d2e41e1c862f5940237293b613d2dadd078c0b4\n",
      "  Running setup.py bdist_wheel for click-plugins ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/70/d7/3d/188128669f2aa42f6008217d9e2e6826d398dc3e361c0fcb75\n",
      "Successfully built pyproj munch click-plugins\n",
      "Installing collected packages: shapely, descartes, pyproj, munch, click-plugins, cligj, fiona, geopandas\n",
      "Successfully installed click-plugins-1.0.3 cligj-0.4.0 descartes-1.1.0 fiona-1.7.9.post1 geopandas-0.3.0 munch-2.2.0 pyproj-1.9.5.1 shapely-1.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the Data\n",
    "Let's grab the data we will need this week from our course website and save it into our data folder. If you've not already created a data folder then do so using the following command. \n",
    "\n",
    "Don't worry if it generates an error, that means you've already got a data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory 'data': File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory 'data/wk8': File exists\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  156k  100  156k    0     0   142k      0  0:00:01  0:00:01 --:--:--  142k\n"
     ]
    }
   ],
   "source": [
    "!mkdir data/wk8\n",
    "!curl https://s3.eu-west-2.amazonaws.com/qm2/wk8/tweet_data.csv -o ./data/wk8/tweet_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`------------------------------`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pylab\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "pylab.rcParams['figure.figsize'] = (10, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point and Areal Data\n",
    "\n",
    "We're going to look at some *point data*, data which has a spatial location but not an extent - this can be contrasted with *areal data*, where data is reported or represented as covering, or relating to, a specific region geography. An example of this second category would be the released census geography - which, as we saw earlier in the term, is reported on a bespoke areal unit called the Output Area.\n",
    "\n",
    "Today we will look at point data. For the purpose, we'll be looking at some data from twitter - data which has detailed spatial position as well as time and date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The birds sing a pretty song\n",
    "\n",
    "Let's start by loading in the twitter data and running head() to take a look at what the dataset contains. The dataset has information about tweeters but not the content of the tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"./data/wk8/tweet_data.csv\"\n",
    "\n",
    "tweets = pandas.DataFrame.from_csv(data_path, parse_dates=[1], infer_datetime_format=True)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "What does each data column represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with datetime data\n",
    "Datetime data is a little trickier to work with - it has structure which allows the extraction of hours, minutes, seconds, and so on. For example, we can just take the time part: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets['dateT'].dt.time.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "What temporal extent does the data cover? How do we need to structure our approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Create a new column in the dataframe which stores the \"minute\" component of the timestamp, and use it to create a histogram of the data over the course of an hour in five minute intervals. Make sure that your graph includes a title and labelled axes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also execuate this code in one line if you don't mind seeing a lot of dots - I've not included the parameters to give this some polish -  we will leave that as an exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets['dateT'].dt.minute.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My First Map\n",
    "The beauty of this data is that the data points have x and y values, so plotting them as a scatter graph will give us out first approximation (with caveats) of a map of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets.plot(\n",
    "    kind='scatter',\n",
    "    x='Lon',\n",
    "    y='Lat',\n",
    "    title=\"Location of Tweets\")\n",
    "plt.xlabel(\"Longitude [degrees]\")\n",
    "plt.ylabel(\"Latitude [degrees]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we've laid out the code so it's easier to see the multiple arguments in plot() - this is just the same as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets.plot(kind='scatter',x='Lon',y='Lat', title=\"Location of Tweets\")\n",
    "plt.xlabel(\"Longitude [degrees]\")\n",
    "plt.ylabel(\"Latitude [degrees]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Change the style of the above map using the optional arguments:\n",
    "\n",
    "- *alpha = *: to set the opacity - 1 being opaque and 0 being transparent. Set the transparecny so that you can see busy areas *and* individual points\n",
    "- *color=*: to set the colo*u*r to 'red'\n",
    "- *s=*: so set the point size to 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have something that looks a bit like a heat map, and even looks a bit Gaussian. Let's see what a histogram of this data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets['Lat'].hist(bins = 50)\n",
    "plt.xlabel(\"Latitude [degrees]\")\n",
    "plt.ylabel(\"Number of Tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = tweets['Lon'].hist(bins=50)\n",
    "plt.xlabel(\"Longitude [degrees]\")\n",
    "ax.set_ylabel(\"Number of Tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Naivest Projection\n",
    "\n",
    "The above tweet plot implicitly uses the *equirectangular* projection, which maps longitude onto the x axis, and latitude onto the y axis. What is the problem with this ? \n",
    "\n",
    "Projection is hugely complex and mathematically fiddly - luckily, we'll be working with packages which mostly do the heavy lifting for us. It's still worth thinking about projection a bit, as the process of taking points on a sphere and translating that to a flat surface is never a perfect one.\n",
    "\n",
    "If  we look at the picture below, then clearly the distance between $p$ and $q$ is the length of the curve on the sphere rather than the straight line between them. The closer $p$ and $q$ are the more the distance is like a straight line, and we can use a *linear mapping* - i.e. the x coordinate is a linear function of lon, and the y axis is a linear function of latitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"https://s3.eu-west-2.amazonaws.com/qm2/wk8/great-circle-distance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension: Not-so-great circles\n",
    "\n",
    "Calculating great circle distances is the \"real\" way of figuring out the distance between two points on a sphere is fairly complex. Thankfully, there's a small angle approximation. \n",
    "\n",
    "If the two points (1 and 2) have latitudes $\\phi_1$ and $\\phi_2$ and longitudes $\\lambda_1$ and $\\lambda_2$, then let $\\Delta\\phi = \\phi_1 - \\phi_2$ and $\\Delta\\lambda = \\lambda_1 - \\lambda_2$ , where $(\\phi_1,\\lambda_1) ,(\\phi_2,\\lambda_2)$ are two points given in (latitude, longitude).  \n",
    "\n",
    "If $\\Delta\\phi$ and $\\Delta\\lambda$ are small enough, you can calculate the distance $D$ with : \n",
    "\n",
    "$$D = R \\sqrt{(\\Delta\\phi)^2+(cos(\\bar{\\phi})\\Delta\\lambda)^2}$$\n",
    "\n",
    "\n",
    "where $\\bar{\\phi}$ is the mean latitude of the two points, $\\frac{1}{2}(\\phi_1+\\phi_2)$, and R is the radius of the earth. \n",
    "\n",
    "How small is small enough if we want to use this approximation? Well, it depends on how much error you want to incur. But generally if the angles are much less than one radian, you'll incur small errors. Radians, you say? Yes, everything in the above equations assumes angles are expressed in radians. 1 radian is about 57 degrees, but there are more precise definitions, and python has a utility function for converting between the two.\n",
    "\n",
    "For reference, the errors accumulated over the size of London are tens of metres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## British Values\n",
    "\n",
    "The British National Grid provides projected values in metres, so we can get by without doing projections \"on the fly\" just yet. If we plot these values, it will look pretty similar, for the reasons outlined above - over the few km of London, most projection methods are quite close to the linear mapping we've done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = tweets.plot(\n",
    "    kind='scatter',\n",
    "    x='OSGB_Lon',\n",
    "    y='OSGB_Lat',\n",
    "    title=\"Location of Tweets\")\n",
    "ax.set_xlabel(\"projected Longitude\")\n",
    "ax.set_ylabel(\"projected Latitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Describing the Data\n",
    "\n",
    "1) Find the data centroid (lat, lon)\n",
    "\n",
    "2) Calculate the x, y and total extent of the data, in km (or miles). (Use the projected [OSGB] data for that.)\n",
    "\n",
    "Hint: use commands which capture the maximum, minimum and mean of the data - describe() is a useful one here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "How might we go about calculating the geographical extent which contained 95% of tweets? Assuming the distribution is Gaussian in both variables, estimate a) the latitude the limits which contain 95% of tweets, b) the longitude limits which contain 95% of tweets. Then c) and add lines showing these limits to the tweet graph and d) save the figure as an image using plt.savefig(*filename*).\n",
    "\n",
    "What proportion of tweets is held within this box?\n",
    "\n",
    "How do you think the following elements influence the above result?\n",
    "\n",
    "- The 2D nature of the data\n",
    "\n",
    "- Asymmetry of the Gaussian (i.e. if $\\sigma_x \\neq \\sigma_y$)\n",
    "\n",
    "- Whether the data is Gaussian!\n",
    "\n",
    "- What other approaches could you take with this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Image(\"https://s3.eu-west-2.amazonaws.com/qm2/wk8/tweets.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working in 2D\n",
    "\n",
    "It's clear that we can learn from 1D about how we can approach 2D data. But there are limitations, and treating 2D as two sets of 1D data doesn't work for everything. We need to find ways to carry out histograms and other aggregations in 2D - and the first of these is hexbinning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hexbinning\n",
    "\n",
    "We can also use a [hexbin clustering](http://pandas-docs.github.io/pandas-docs-travis/visualization.html#hexagonal-bin-plot) method, which is similar to binning in a histogram, the more points we have in hexbin the warmer the color. Here, we count the number data points in each hexagons, in the same way that we count the number of data in each bin for 1D data\n",
    "\n",
    "Luckily, the code is very easy to execute, and requires only small changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = tweets.plot(\n",
    "    kind='hexbin',\n",
    "    x='OSGB_Lon', y='OSGB_Lat',\n",
    "    gridsize=50,\n",
    "    title=\"Tweet Density (Hex Bin)\",\n",
    "    cmap='coolwarm',\n",
    "    )\n",
    "plt.xlabel(\"projected Longitude\")\n",
    "plt.ylabel(\"projected Latitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible values are: Spectral, summer, coolwarm, Wistia_r, pink_r, Set1, Set2, Set3, brg_r, Dark2, prism, PuOr_r, afmhot_r, terrain_r, PuBuGn_r, RdPu, gist_ncar_r, gist_yarg_r, Dark2_r, YlGnBu, RdYlBu, hot_r, gist_rainbow_r, gist_stern, PuBu_r, cool_r, cool, gray, copper_r, Greens_r, GnBu, gist_ncar, spring_r, gist_rainbow, gist_heat_r, Wistia, OrRd_r, CMRmap, bone, gist_stern_r, RdYlGn, Pastel2_r, spring, terrain, YlOrRd_r, Set2_r, winter_r, PuBu, RdGy_r, spectral, rainbow, flag_r, jet_r, RdPu_r, gist_yarg, BuGn, Paired_r, hsv_r, bwr, cubehelix, Greens, PRGn, gist_heat, spectral_r, Paired, hsv, Oranges_r, prism_r, Pastel2, Pastel1_r, Pastel1, gray_r, jet, Spectral_r, gnuplot2_r, gist_earth, YlGnBu_r, copper, gist_earth_r, Set3_r, OrRd, gnuplot_r, ocean_r, brg, gnuplot2, PuRd_r, bone_r, BuPu, Oranges, RdYlGn_r, PiYG, CMRmap_r, YlGn, binary_r, gist_gray_r, Accent, BuPu_r, gist_gray, flag, bwr_r, RdBu_r, BrBG, Reds, Set1_r, summer_r, GnBu_r, BrBG_r, Reds_r, RdGy, PuRd, Accent_r, Blues, autumn_r, autumn, cubehelix_r, nipy_spectral_r, ocean, PRGn_r, Greys_r, pink, binary, winter, gnuplot, RdYlBu_r, hot, YlOrBr, coolwarm_r, rainbow_r, Purples_r, PiYG_r, YlGn_r, Blues_r, YlOrBr_r, seismic, Purples, seismic_r, RdBu, Greys, BuGn_r, YlOrRd, PuOr, PuBuGn, nipy_spectral, afmhot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension: Splitting Mapping Data by Time\n",
    "\n",
    "In the next section, we use both space and time to show different geographical distributions at different times. We'll select on index, splitting the dataset in two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early = tweets[:750]\n",
    "late = tweets[750:len(tweets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "late.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Plot both sets of tweets onto the same axes so they can be compared. Try and make your plot look like the image below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Image(\"https://s3.eu-west-2.amazonaws.com/qm2/wk8/two_times.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visually inspect the spatial plots of the two time frames using hexbin plots; in this case there's not much to see..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = early.plot(\n",
    "    kind='hexbin',\n",
    "    x='OSGB_Lon', \n",
    "    y='OSGB_Lat',\n",
    "    gridsize=50,\n",
    "    title=\"Tweet Density (Hex Bin)\",\n",
    "    cmap='coolwarm',\n",
    "    )\n",
    "plt.xlabel(\"projected Longitude\")\n",
    "plt.ylabel(\"projected Latitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = late.plot(\n",
    "    kind='hexbin',\n",
    "    x='OSGB_Lon', \n",
    "    y='OSGB_Lat',\n",
    "    gridsize=50,\n",
    "    title=\"Tweet Density (Hex Bin)\",\n",
    "    cmap='coolwarm',\n",
    "    )\n",
    "plt.xlabel(\"projected Longitude\")\n",
    "plt.ylabel(\"projected Latitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
